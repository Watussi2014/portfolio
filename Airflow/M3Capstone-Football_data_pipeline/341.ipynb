{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72515993-9d1f-4154-ba96-3eab30739219",
   "metadata": {},
   "source": [
    "# About this Sprint\n\nIt is time for your third Capstone Project.\nYou will work on this project for the whole Sprint.\nThe outcome of this Sprint should potentially serve as your portfolio item, so try to show your best work!\n\nEven though you have learned a lot about dimensional data modeling, Airflow, Docker, dbt, and data mesh in this Sprint, working on this project will be the real challenge.\n\nGood luck!\n\n*Note:* [advice on building your portfolio](https://turingcollege.atlassian.net/wiki/spaces/DLG/pages/1002307695/Portfolio+Items)\n\n## Context\n\nAll engineering roles have a technical leadership aspect; typically, the importance of the technical leadership skills correlates positively with the seniority of the engineer, i.e. the more senior the engineer, the more important the technical leadership skills are.\n\nOne key competency of a strong technical leader is teaching.\nBesides being an essential skill for any engineer, teaching is also an excellent strategy for mastering technical skills that you have recently learned or are still learning.\nThere are a number of studies that found that one of the most effective ways to learn is to teach others.\n\nFor that purpose, you decided to put what you know about data engineering in a demo project, which you will use to teach data engineering.\n\n**Target audience.** It is up to you to decide what your audience is - it can be people, who are just learning data engineering, people, who have experience but didn't keep you with the latest developments in the field, or even experienced data engineers, who still get some concepts occasionally wrong.\n\n**Topics & technologies.** This demo project should cover the most important aspects of data modeling, data mesh, and other essential data engineering concepts. It is up to you to decide which technologies to use, but we expect that you'd show your proficiency with Airflow, dbt, and Docker.\n\n**Data.** You can use any dataset that you want. You can scrape data, use public APIs, or simply download a dataset.\n\n**Format.** You are free to choose the format of this project yourself - the important part is that the format will enable you to achieve your teaching objective.\nIt might be a proof of concept, reference implementation, a set of best practices supported with code, tutorial, etc. Most likely, your solution will contain the following:\n1. One or more typically a document explaining what you are trying to achieve and why.\n2. Code files (likely dozens) that contain the implementation.\n3. At least one (but likely more) diagram explaining your choices.\n\n**Examples.** These can serve as examples of what acceptable topics might look like. They are deliberately not *very* good, as not to tempt you to simply pick one of them:\n- What are the common mistakes that new data engineers make while implementing dimensional data modeling? This project explains why these mistakes happen and what to do instead.\n- Dimensional data modeling was great when it was created in the 1990s, but some parts of it are outdated. This project explains why some of the advice in The Data Warehouse Toolkit is wrong in today's data engineering and provides alternatives.\n- Is data mesh the answer to all the data engineering woes in the enterprise? This project shows what a minimal data mesh implementation might look like and explains each part.\n- Many freshly minted data engineers believe that adopting the latest data engineering tools or ideas will automatically solve their data processing challenges. This project dives into the misconceptions about modern data engineering tools and offers guidance on how to effectively integrate them without falling into common pitfalls.\n\n## Objectives for this Part\n\n- Practice technical leadership - leveraging what you know about data engineering to teach and influence others.\n- Strengthen your understanding of dimensional data modeling, data mesh, Airflow, Docker, dbt, and Python.\n\n## Requirements\n\n- Your solution should encompass what was outlined in the Context section.\n- Provide suggestions on how your analysis can be improved.\n\n## Bonus Challenges\n\n- Publish a blog post about your project.\n\n## Evaluation Criteria\n\n- Adherence to the requirements. How well did you meet the requirements?\n- Code quality. Is the code modular, with a clear separation of concerns? Is the coding style consistent? Is the code performant? Is it secure?\n- System design. Did your solution use suitable technologies, tools, software architecture, and algorithms?\n- Presentation quality. How comprehensive is your presentation, and how well are you able to explain your solution to the target audience?\n- Conceptual understanding. How well do you know the concepts covered in this and previous Sprints?\n\n## Project Review\n\nDuring your project review, you should present it as if talking to a data engineer.\nYou can assume that they will have decent data engineering skills.\nThey will not be familiar with the problem that you are trying to solve nor the solution that you are presenting - an important part of your evaluation is explaining your solution in a logical sequence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a32c509-47fb-4c94-9637-56fa24dd0e7d",
   "metadata": {},
   "source": [
    "## General Project Review Guidelines\n\nFor an in-depth explanation about how project reviews work at Turing College, please read [this doc](https://turingcollege.atlassian.net/wiki/spaces/DLG/pages/537395951/Peer+expert+reviews+corrections).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
